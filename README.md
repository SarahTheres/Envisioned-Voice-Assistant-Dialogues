# Envisioned Voice Assistant Dialogues

This data set was collected as part of a research project at LMU Munich (Germany), University of Bayreuth (Germany), and the University College Dublin (Ireland). This research project will be published in the proceedings of the ACM CHI Conference on Human Factors in Computing Systems in 2021 (CHI '21). You may find the project website here: http://www.medien.ifi.lmu.de/envisioned-va-dialogues/

The dataset consists of 1,854 written dialogues between a user and a voice assistant, which were envisioned by 205 people in an online survey. In particular, we asked participants to envision and write down dialogues with a *perfect* voice assistant without any technical limitations for nine scenarios (cf. below). In the survey instructions, we highlighted that the conversation could be initiated by both parties, and also provided an example scenario with two example dialogues (one initiated by the user, the other by the voice assistant). Participants were then presented with the eight different scenarios in random order before concluding with an open scenario, where they were given the opportunity to think of another situation where they would like to use the perfect voice assistant. For each scenario, participants were asked to first select who is speaking from a dropdown menu ("You" or "Voice assistant") and then write down what the selected speaker is saying).

## Scenarios
We prompted participants with eight scenarios. These scenarios were based on the most popular use cases for Google Home and Amazon Alexa / Echo as recently identified by <a href="https://dl.acm.org/doi/abs/10.1145/3311956">Ammari et al. (2019)</a> from 250,00 command logs of users interacting with smart speakers. In addition, we included an open scenario where participants could describe a situation in which they would like to use a voice assistant. Each scenario contained a descriptive part and a specific issue which participants should address and solve in their envisioned dialogue between a user and a perfect voice assistant.

These are the scenarios:
<table>
  <tr>
    <th>Name</th>
    <th>Description & Issue</th>
  </tr>
  <tr>
    <td>Search</td>
    <td>You want to go to the cinema to see a film, but you do not know the film times for your local cinema.</td>
  </tr>
  <tr>
    <td>Music</td>
    <td>You are cooking dinner. You are on your own and you like to listen to some music while cooking.</td>
  </tr>
  <tr>
    <td>Internet of Things</td>
    <td>You are going to bed. You like to read a book before going to sleep. You often fall asleep with the lights on.</td>
  </tr>
  <tr>
    <td>Volume</td>
    <td>You are listening to loud music, but your neighbours are sensitive to noise.</td>
  </tr>
  <tr>
    <td>Weather</td>
    <td>You are planning a trip to Italy in two days but do not know what kind of clothing to pack. You like to be prepared for the weather. </td>
  </tr>
  <tr>
    <td>Joke</td>
    <td>You and your friends are hanging out. You like to entertain your friends, but the group seems to have run out of funny stories.</td>
  </tr>
  <tr>
    <td>Conversational</td>
    <td>You are going to bed, but you are having trouble falling asleep.</td>
  </tr>
  <tr>
    <td>Alarm</td>
    <td>You are going to bed. You have an important meeting early next morning, and you tend to oversleep.</td>
  </tr>
  <tr>
    <td>Open Scenario</td>
    <td>Participants were asked to think about another situation in which they would like to use the perfect voice assistant.</td>
  </tr>
</table>

## Questionnaires
In addition to writing down dialogues between a user and a voice assistant, we also asked participants about their experience with existing voice assistants and for demographic infromation. Furthermore, participants filled out the 60 items Big Five Inventory-2 personality questionnaire by <a href="https://psycnet.apa.org/record/2016-17156-001">Soto and John (2017)</a>. 

## Participants
We recruited participants using the crowdsourcing web platform <a href="https://www.prolific.co">Prolific</a>. After excluding three participants due to incomplete answers, our sample consisted of 205 participants from the UK (48.8% male, 50.7% female, 0.5% non-binary, mean age 36.2 years, range: 18--80 years). 

## Reference
A full description of our research design, data collection, and analyses can be found in the paper below. Please cite this paper in your work where relevant. 

```
@inproceedings{voelkel2021,
author = {V\"{o}lkel, Sarah Theres and Buschek, Daniel and Eiband, Malin and Cowan, Benajming R. and Hussmann, Heinrich},
title = {Eliciting and Analysing Users' Envisioned Dialogues with Perfect Voice Assistants},
year = {2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
location = {Yokohama, Japan},
series = {CHI '21}
}
```

## Copyright
This is the work of Sarah Theres VÃ¶lkel, Daniel Buschek, Malin Eiband, Benjamin R. Cowan, and Heinrich Hussmann from LMU Munich, University of Bayreuth, and University College Dublin, made available under the <a href="https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 License</a>. 


# Explanation of Data Files



## Note on dialogues
In a separate task, transcription of crowdsourced user utterances from the two-person dialogs were checked for errors but may still include an occasional typo, misspelling or ungrammatical sequence. In cases where a dialog failed to make sense, workers doing these corrections were given the freedom to insert or delete turns or replace entire phrases with language that made the dialog follow a more sensible path. Shorthand typing conventions originally used by the call center operators such as 'cuz', 'lol' and other non-standard English phrases were left as is. Disfluencies such as 'they um, they want Korean cuisine' were also usually transcribed as spoken, but sometimes transcribers corrected them.

# Contact
In case you have any comments or questions, please contact sarah.voelkel@ifi.lmu.de
